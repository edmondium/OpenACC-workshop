{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSC OpenACC Course 2024\n",
    "\n",
    "* Date: 29 - 31 October 2024\n",
    "* Location: _online_\n",
    "* Institue: JÃ¼lich Supercomputing Centre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 6: Multi GPU Programming with MPI and OpenACC \n",
    "\n",
    "### Task 1 Apply domain decomposition\n",
    "\n",
    "* Handle GPU affinity \n",
    "* Halo Exchange\n",
    "\n",
    "Follow `TODO`s in `6-Multi-GPU-Programming-with-MPI_and_OpenACC/exercises/[C|FORTRAN]/task1/poisson2d.[c|F03]`\n",
    "\n",
    "#### Make Targets\n",
    "\n",
    "* `run`: run `poisson2d` (default)\n",
    "* `poisson2d`: build `poisson2d` binary\n",
    "* `profile`: profile with [Nsight Systems](https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-profiling)\n",
    "* `*.solution`: same as above with solution (`poisson2d.solution.*`)\n",
    "\n",
    "#### Example Output\n",
    "\n",
    "```console\n",
    "[kraus1@jwlogin21 task1]$ make\n",
    "mpicc -c -DUSE_DOUBLE -Minfo=accel -fast -acc=gpu -gpu=cc80 poisson2d_serial.c -o poisson2d_serial.o\n",
    "poisson2d_serial:\n",
    "     37, Generating present(Anew[:],rhs[:],Aref[:])\n",
    "     39, Generating update device(rhs[:ny*nx],Aref[:ny*nx])\n",
    "     41, Generating Tesla code\n",
    "         44, #pragma acc loop gang /* blockIdx.x */\n",
    "             Generating implicit reduction(max:error)\n",
    "         46, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "     41, Generating implicit copy(error) [if not already present]\n",
    "     46, Loop is parallelizable\n",
    "     52, Generating Tesla code\n",
    "         55, #pragma acc loop gang /* blockIdx.x */\n",
    "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "     57, Loop is parallelizable\n",
    "     61, Generating Tesla code\n",
    "         65, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "     69, Generating Tesla code\n",
    "         71, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "     82, Generating update self(Aref[:ny*nx])\n",
    "mpicc -DUSE_DOUBLE -Minfo=accel -fast -acc=gpu -gpu=cc80 poisson2d.c poisson2d_serial.o -o poisson2d\n",
    "poisson2d.c:\n",
    "\"poisson2d.c\", line 164: warning: variable \"top\" was declared but never referenced\n",
    "          int top    = (rank == 0) ? (size-1) : rank-1;\n",
    "              ^\n",
    "\n",
    "\"poisson2d.c\", line 165: warning: variable \"bottom\" was declared but never referenced\n",
    "          int bottom = (rank == (size-1)) ? 0 : rank+1;\n",
    "              ^\n",
    "\n",
    "main:\n",
    "     72, Generating enter data create(rhs[:ny*nx],Aref[:ny*nx],A[:ny*nx],Anew[:ny*nx])\n",
    "     77, Generating present(Aref[:],Anew[:],A[:])\n",
    "         Generating Tesla code\n",
    "         81, #pragma acc loop gang /* blockIdx.x */\n",
    "         83, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "     83, Loop is parallelizable\n",
    "     93, Generating update self(A[:ny*nx],Anew[:ny*nx],Aref[:ny*nx])\n",
    "    128, Generating update device(rhs[nx*iy_start:nx*(iy_end-iy_start)],A[nx*(iy_start-1):nx*((iy_end-iy_start)+2)])\n",
    "    130, Generating present(A[:],rhs[:],Anew[:])\n",
    "         Generating Tesla code\n",
    "        133, #pragma acc loop gang /* blockIdx.x */\n",
    "             Generating implicit reduction(max:error)\n",
    "        135, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "    130, Generating implicit copy(error) [if not already present]\n",
    "    135, Loop is parallelizable\n",
    "    145, Generating present(Anew[:],A[:])\n",
    "         Generating Tesla code\n",
    "        148, #pragma acc loop gang /* blockIdx.x */\n",
    "        150, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "    150, Loop is parallelizable\n",
    "    154, Generating present(A[:])\n",
    "         Generating Tesla code\n",
    "        159, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "    179, Generating present(A[:])\n",
    "         Generating Tesla code\n",
    "        182, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "    193, Generating update self(A[nx*(iy_start-1):nx*((iy_end-iy_start)+2)])\n",
    "    212, Generating exit data delete(rhs[:1],Aref[:1],A[:1],Anew[:1])\n",
    "/p/software/juwelsbooster/stages/2020/software/binutils/2.36.1-GCCcore-10.3.0/bin/ld: warning: /p/software/juwelsbooster/stages/2020/software/NVHPC/21.9-GCC-10.3.0/Linux_x86_64/21.9/compilers/lib/nvhpc.ld contains output sections; did you forget -T?\n",
    "srun --ntasks-per-node 4 -n 4 ./poisson2d\n",
    "Jacobi relaxation Calculation: 8192 x 8192 mesh\n",
    "Calculate reference solution and time serial execution.\n",
    "    0, 0.250000\n",
    "  100, 0.249985\n",
    "  200, 0.249970\n",
    "  300, 0.249955\n",
    "  400, 0.249940\n",
    "  500, 0.249925\n",
    "  600, 0.249911\n",
    "  700, 0.249896\n",
    "  800, 0.249881\n",
    "  900, 0.249866\n",
    "Parallel execution.\n",
    "    0, 0.250000\n",
    "  100, 0.249985\n",
    "  200, 0.249970\n",
    "  300, 0.249955\n",
    "  400, 0.249940\n",
    "  500, 0.249925\n",
    "  600, 0.249911\n",
    "  700, 0.249896\n",
    "  800, 0.249881\n",
    "  900, 0.249866\n",
    "Num GPUs: 4.\n",
    "8192x8192: 1 GPU:   2.3271 s, 4 GPUs:   2.3426 s, speedup:     0.99, efficiency:    24.84%\n",
    "MPI time:   0.0000 s, inter GPU BW:  6604.84 GiB/s\n",
    "```\n",
    "\n",
    "### Task 2 Hide MPI communication time\n",
    "\n",
    "* Start copy loop asynchronously \n",
    "* Wait for async copy loop after MPI communication is done\n",
    "\n",
    "Follow `TODO`s in `6-Multi-GPU-Programming-with-MPI_and_OpenACC/exercises/[C|FORTRAN]/task2/poisson2d.c`\n",
    "\n",
    "#### Make Targets\n",
    "\n",
    "* `run`: run `poisson2d` (default)\n",
    "* `poisson2d`: build `poisson2d` binary\n",
    "* `profile`: profile with [Nsight Systems](https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-profiling)\n",
    "* `*.solution`: same as above with solution (`poisson2d.solution.*`)\n",
    "\n",
    "#### Example Output\n",
    "\n",
    "```console\n",
    "[kraus1@jwlogin21 task2]$ make\n",
    "mpicc -c -DUSE_DOUBLE -Minfo=accel -fast -acc=gpu -gpu=cc80 poisson2d_serial.c -o poisson2d_serial.o\n",
    "poisson2d_serial:\n",
    "     37, Generating present(Anew[:],rhs[:],Aref[:])\n",
    "     39, Generating update device(rhs[:ny*nx],Aref[:ny*nx])\n",
    "     41, Generating Tesla code\n",
    "         44, #pragma acc loop gang /* blockIdx.x */\n",
    "             Generating implicit reduction(max:error)\n",
    "         46, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "     41, Generating implicit copy(error) [if not already present]\n",
    "     46, Loop is parallelizable\n",
    "     52, Generating Tesla code\n",
    "         55, #pragma acc loop gang /* blockIdx.x */\n",
    "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "     57, Loop is parallelizable\n",
    "     61, Generating Tesla code\n",
    "         65, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "     69, Generating Tesla code\n",
    "         71, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "     82, Generating update self(Aref[:ny*nx])\n",
    "mpicc -DUSE_DOUBLE -Minfo=accel -fast -acc=gpu -gpu=cc80 poisson2d.c poisson2d_serial.o -o poisson2d\n",
    "poisson2d.c:\n",
    "main:\n",
    "     82, Generating enter data create(Aref[:ny*nx],rhs[:ny*nx],A[:ny*nx],Anew[:ny*nx])\n",
    "     93, Generating present(Aref[:],Anew[:],A[:])\n",
    "         Generating Tesla code\n",
    "         97, #pragma acc loop gang /* blockIdx.x */\n",
    "         99, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "     99, Loop is parallelizable\n",
    "    109, Generating update self(A[:ny*nx],Aref[:ny*nx],Anew[:ny*nx])\n",
    "    144, Generating update device(rhs[nx*iy_start:nx*(iy_end-iy_start)],A[nx*(iy_start-1):nx*((iy_end-iy_start)+2)])\n",
    "    146, Generating present(A[:],rhs[:],Anew[:])\n",
    "         Generating Tesla code\n",
    "        149, #pragma acc loop gang /* blockIdx.x */\n",
    "             Generating implicit reduction(max:error)\n",
    "        151, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "    146, Generating implicit copy(error) [if not already present]\n",
    "    151, Loop is parallelizable\n",
    "    161, Generating present(Anew[:],A[:])\n",
    "         Generating Tesla code\n",
    "        165, #pragma acc loop gang /* blockIdx.x */\n",
    "        167, #pragma acc loop vector(128) /* threadIdx.x */\n",
    "    167, Loop is parallelizable\n",
    "    190, Generating present(A[:])\n",
    "         Generating Tesla code\n",
    "        194, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
    "    205, Generating update self(A[nx*(iy_start-1):nx*((iy_end-iy_start)+2)])\n",
    "    224, Generating exit data delete(rhs[:1],Aref[:1],A[:1],Anew[:1])\n",
    "/p/software/juwelsbooster/stages/2020/software/binutils/2.36.1-GCCcore-10.3.0/bin/ld: warning: /p/software/juwelsbooster/stages/2020/software/NVHPC/21.9-GCC-10.3.0/Linux_x86_64/21.9/compilers/lib/nvhpc.ld contains output sections; did you forget -T?\n",
    "srun --ntasks-per-node 4 -n 4 ./poisson2d\n",
    "Jacobi relaxation Calculation: 8192 x 8192 mesh\n",
    "Calculate reference solution and time serial execution.\n",
    "    0, 0.250000\n",
    "  100, 0.249985\n",
    "  200, 0.249970\n",
    "  300, 0.249955\n",
    "  400, 0.249940\n",
    "  500, 0.249925\n",
    "  600, 0.249911\n",
    "  700, 0.249896\n",
    "  800, 0.249881\n",
    "  900, 0.249866\n",
    "Parallel execution.\n",
    "    0, 0.250000\n",
    "  100, 0.249985\n",
    "  200, 0.249970\n",
    "  300, 0.249955\n",
    "  400, 0.249940\n",
    "  500, 0.249925\n",
    "  600, 0.249911\n",
    "  700, 0.249896\n",
    "  800, 0.249881\n",
    "  900, 0.249866\n",
    "Num GPUs: 4.\n",
    "8192x8192: 1 GPU:   2.3268 s, 4 GPUs:   0.6757 s, speedup:     3.44, efficiency:    86.09%\n",
    "MPI time:   0.0367 s, inter GPU BW:     6.65 GiB/s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
